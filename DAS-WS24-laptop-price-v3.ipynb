{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X77D6C1-cnJ"
   },
   "source": [
    "# Linear Regression \"laptop price\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PShTtzzyiWei"
   },
   "source": [
    "# 1&nbsp;Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHWI1zkj-cnM"
   },
   "source": [
    "\n",
    "The contents of this notebook are divided into various categories which are given as follows:\n",
    "\n",
    "<ol>\n",
    "<li><b>Table of contents</b>\n",
    "<li><b>Background</b>\n",
    "<li><b>Business Understanding</b>\n",
    "<li><b>Import required libraries</b>\n",
    "<li><b>Import data and check import</b><br>\n",
    "    5.1 Import Data<br>\n",
    "    5.2 Check Import<br>\n",
    "<li><b>First Data Preparation for Analysis</b><br>\n",
    "    6.1 Remove unwanted columns (optional)<br>\n",
    "    6.2 Rename column names (optional)<br>\n",
    "    6.3 Check and handle Null values<br>\n",
    "    6.4 Check and change data types<br>\n",
    "    6.5 Remove special characters<br>\n",
    "    6.6 Replace values<br>\n",
    "    6.7 Replace rare values<br>\n",
    "\n",
    "<li><b>Data Understanding</b><br>\n",
    "    7.1 Univariate - statistical analysis<br>\n",
    "    7.2 Univariate - visualizations<br>\n",
    "    7.3 Bivariate - correlation matrix<br>\n",
    "    7.4 Bivariate - visualization<br>\n",
    "    7.5 Trivariate - visualization<br>\n",
    "\n",
    "<li><b>Data Preparation</b><br>\n",
    "    8.1 Feature Engineering<br>\n",
    "    8.2 Scaling<br>\n",
    "    8.3 Delete data records\n",
    "\n",
    "<li><b>Split data (Train and Test)</b>\n",
    "\n",
    "<li><b>Create Linear Models</b><br>\n",
    "    10.1 Fit Linear Models<br>\n",
    "    10.2 Visual check<br>\n",
    "    10.3 Statistical' check<br>\n",
    "    10.4 Summary table - upper area<br>\n",
    "    10.5 Summary table - middle area<br>\n",
    "    10.6 Summary table - lower area<br>\n",
    "\n",
    "<li><b>Check performance with test data</b>\n",
    "    11.1 Handling extra categories in test set\n",
    "    11.2 Check R2 and RMSE for test\n",
    "    11.3 Residual plot (test)\n",
    "\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-4VbS8mEsUJ"
   },
   "source": [
    "# 2&nbsp;Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jbi3qK8D-YPS"
   },
   "source": [
    "<ul>\n",
    "<li>The data set is available via the following link:<br>\n",
    "https://www.kaggle.com/datasets/muhammetvarl/laptop-price\n",
    "<li>The data was uploaded 4 years ago.\n",
    "<li>This dataset provides a comprehensive collection of information on various laptops, enabling a detailed analysis of their specifications and pricing.\n",
    "<li>It encompasses a wide range of laptops, encompassing diverse brands, models, and configurations, making it a valuable resource for researchers, data analysts, and machine learning enthusiasts interested in the laptop industry.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7J_iJsN0_lCp"
   },
   "source": [
    "# 3 Business understanding<br>\n",
    "<ul>\n",
    "<li>The task is to analyze the selling price of laptops depending on their characteristics.\n",
    "<li>The aim is to develop a linear regression equation with which the individual prices can be estimated as well as possible.\n",
    "<li>This equation can then be used to estimate which of these laptops are rather expensive and which are rather cheap.\n",
    "<li>In addition, the expected price of a laptop with certain features can be estimated.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpYR931gA4PD"
   },
   "source": [
    "<b>Question:</b><br>\n",
    "<ul>\n",
    "<li>Is this a supervised or unsupervides learning task?\n",
    "<li>Is it classification or regression?\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjzhtqoRBmKo"
   },
   "source": [
    "<b>Selecting a performance measure</b><br>\n",
    "<ul>\n",
    "<li>Can you remember the target function of the linear regression?\n",
    "<li>Is this target function also useful here?\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWmzlwzc7GqG"
   },
   "source": [
    "Each line in the file <b>laptop-price-DAS.csv</b> represents the features and selling price of a laptop.<br>\n",
    "It contains 1275 laptops and the following 15 columns:<br>\n",
    "\n",
    "\\begin{array}{|l|l|l|} \\hline\n",
    "\\textbf{Company} & String & \\text{Laptop Manufacturer} \\\\ \\hline\n",
    "\\textbf{Product} & String & \\text{Brand and Model} \\\\ \\hline\n",
    "\\textbf{TypeName} & String & \\text{Type (Notebook, Ultrabook, Gaming, etc.)} \\\\ \\hline\n",
    "\\textbf{Inches} & Numeric & \\text{Screen Size} \\\\ \\hline\n",
    "\\textbf{ScreenResolution} & String & \\text{Screen Resolution} \\\\ \\hline\n",
    "\\textbf{CPU_Company} & String & \\text{CPU Maufacturer} \\\\ \\hline\n",
    "\\textbf{CPU_Type} & String & \\text{CPU Type} \\\\ \\hline\n",
    "\\textbf{CPU_Frequency} & Numeric & \\text{CPU Frequency in GHz} \\\\ \\hline\n",
    "\\textbf{RAM} & String & \\text{RAM in GB} \\\\ \\hline\n",
    "\\textbf{Memory} & String & \\text{Hard Disk / SSD Memory} \\\\ \\hline\n",
    "\\textbf{GPU_Company} & String & \\text{GPU Manufacturer} \\\\ \\hline\n",
    "\\textbf{GPU_Type} & String & \\text{GPU Type} \\\\ \\hline\n",
    "\\textbf{OpSys} & String & \\text{OPerating System} \\\\ \\hline\n",
    "\\textbf{Weight} & Numeric & \\text{Weight in kg} \\\\ \\hline\n",
    "\\textbf{Price} & Numeric & \\text{Price in Euro} \\\\ \\hline\n",
    "\\end{array}\n",
    "<br>The columns are separated by a comma. A point is used as the decimal separator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1iW3Chl-cnR"
   },
   "source": [
    "# 4&nbsp;Import required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytK3YmPOG5_T"
   },
   "source": [
    "<b>Brief description of the used libraries</b><br>\n",
    "<ul>\n",
    "<li><b>numpy (numerical python):</b><br>\n",
    "supports <b>efficient numerical operations</b> on large quantities of data.\n",
    "<li><b>pandas (dervived from 'panel data'):</b><br>\n",
    "is a very popular library for working with data.<br>\n",
    "DataFrames are at the center of pandas.<br>\n",
    "It is based on nnumpy.\n",
    "<li><b>matplotlib:</b><br>\n",
    "is a library for creating static, animated, and interactive <b>visualizations</b>.\n",
    "<li><b>seaborn:</b><br>\n",
    "is a data <b>visualization</b> library based on matplotlib.<br>\n",
    "It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "<li><b>sklearn (scikit-learn)</b><br>\n",
    "Built on NumPy, SciPy, and matplotlib<br>\n",
    "Simple and efficient tools for predictive data analysis\n",
    "<li><b>statsmodels</b><br>\n",
    "provides classes and functions for the estimation of many different statistical models,<br>\n",
    "as well as for conducting statistical tests, and statistical data exploration.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLY7pm_4-cnS"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m                                   \u001b[38;5;66;03m# for numerical operations\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m                                  \u001b[38;5;66;03m# for dataframe operations\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m                      \u001b[38;5;66;03m# for plotting and visualisations\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m                                \u001b[38;5;66;03m# for plotting and visualisations - sometimes nicer than plt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression    \u001b[38;5;66;03m# sklearn implementation of linear regression\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# import Python libraries\n",
    "import numpy as np  # for numerical operations\n",
    "import pandas as pd  # for dataframe operations\n",
    "import matplotlib.pyplot as plt  # for plotting and visualisations\n",
    "import seaborn as sns  # for plotting and visualisations - sometimes nicer than plt\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    ")  # sklearn implementation of linear regression\n",
    "from sklearn.metrics import r2_score  # calcuation of R2\n",
    "from sklearn.metrics import root_mean_squared_error  # calcuation of RMSE\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")  # split a dataset in training and test\n",
    "import statsmodels.api as sm  # statsmodel implementation of linear regression\n",
    "import statsmodels.formula.api as smf  # to use formular in linear regression ('R-Style')\n",
    "import sys  # access to some variables used or maintained by the interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwfZ954SATHI"
   },
   "source": [
    "# 5.&nbsp;Import Data and check import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNG7v21aMZi_"
   },
   "source": [
    "## 5.1&nbsp;Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pr-me2H8R8o"
   },
   "source": [
    "**(A) For Colab-Users and loading from your local drive:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVSr82uQEs-t"
   },
   "source": [
    "The code will prompt you to select a file.<br>\n",
    "Click on “Choose Files” then select the file to be imported (e.g., 'housing-california.csv').<br>\n",
    "<b>Wait for the file to be 100% uploaded.</b><br>\n",
    "You should see the name of the file once Colab has uploaded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1VHxAJVEf1D"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if \"google.colab\" in sys.modules:   # checks if google is used\n",
    "  from google.colab import files\n",
    "  uploaded = files.upload()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ542PNlYFTs"
   },
   "source": [
    "<b>After executing this code cell, it should be commented out.</b><br>\n",
    "This can be done with ''' at the beginning and at the end of that call.</b>\n",
    "Advantage: you can run the code again and again from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A2YoDJGFMvM"
   },
   "source": [
    "The following code imports the file (that is uploaded in google drive) into a DataFrame.<br>\n",
    "Make sure the filename in the code matches the name of the uploaded file - tip: copy the filename with extension (after 'to').<br>\n",
    "sep: stands for separator for the columns - adjust if necessary<br>\n",
    "decimals: decimal point - adjust if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbirDpjuFVLy"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    file = \"laptop-price-DAS.csv\"  # change filename\n",
    "\n",
    "    import io\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        io.BytesIO(uploaded[file]), sep=\",\", decimal=\".\"\n",
    "    )  # change values for sep and decimal\n",
    "    # Dataset is now stored in a Pandas Dataframe named df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwYbE9uS-Kym"
   },
   "source": [
    "**(B) For Colab-Users and loading from Google Drive:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuVO8ldV4DVM"
   },
   "source": [
    "<b>In this case, you have to remove \"#\" in this section (B)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wxmc6ena-dQj"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2qAlUZ75Ooe"
   },
   "source": [
    "Click on the folder-symbol on the left side (onmouseover: \"files\" is shown).<br>\n",
    "Then you can see folders and files under \"content/drive\".<br>\n",
    "Go through the folders und look for the file you want to import.<br> Mark the file, and klick on the \"three points\". Click on \"copy path\".<br>\n",
    "Copy the copied path in the following code cell like in the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EL69vbM_wld"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/drive/MyDrive/DAS/Regression/Housing/housing-california.csv',sep=',', decimal= '.')#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oMtiaTi8cJ5"
   },
   "source": [
    "**(C) For those, who do not use Colab:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YO8NYAS6Caj"
   },
   "source": [
    "<b>In this case, you have to remove one \"#\" in the following code cell,<br>\n",
    "and adjust the path.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-Tue6cM8jSh"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'C:/data_folder/house-california.csv')   # absolute path\n",
    "# df = pd.read_csv(\"../data_folder/house-cailfornia.csv\")    # relative path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_2Nmj2a-cnU"
   },
   "source": [
    "## 5.2&nbsp;Check import</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p05ogJznBy1a"
   },
   "source": [
    "<b>pandas.DataFrame.info</b><br>\n",
    "This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89Z9989PBguK"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_4ZfjIrCNvd"
   },
   "source": [
    "<b>pandas.DataFrame.sample</b><br>\n",
    "Return a random sample of items from an axis of object.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qMWnL66-cnV"
   },
   "outputs": [],
   "source": [
    "df.sample(3)  # show three randomly selected rows with all cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5k-msuxCvaD"
   },
   "source": [
    "<b>pandas.DataFrame.shape</b><br>\n",
    "Return a tuple representing the dimensionality of the DataFrame.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtI2nBs5-cnU"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqgE3spHZH9S"
   },
   "source": [
    "# 6&nbsp;First Data Preparation for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBR5yqHYDhp2"
   },
   "source": [
    "## 6.1&nbsp;Remove unwanted columns (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYK4tOSbGEqb"
   },
   "source": [
    "<b>pandas.DataFrame.drop</b><br>\n",
    "Remove rows or columns by specifying label names and corresponding axis, or by directly specifying index or column names.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ho2VNb8DqNN"
   },
   "source": [
    "Columns that are not needed can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vomoCvjBV7Y"
   },
   "outputs": [],
   "source": [
    "# df = df.drop('name_of_column_to_be_dropped', axis = 1)          # axis = 1:  means columns (axis=0 are rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtXwM4BWEChk"
   },
   "source": [
    "## 6.2&nbsp;Rename column names (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N46vG5KMHh5D"
   },
   "source": [
    "<b>pandas.DataFrame.columns</b><br>\n",
    "The column labels of the DataFrame.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnynjQJn-cnW"
   },
   "source": [
    "If the column names are very long or include white spaces,<br>\n",
    "it makes sense to rename them.<br>\n",
    "We save the long names for the possible later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlDHmIMkZI7y"
   },
   "source": [
    "i prefer column names with lower case letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-Gvv_ZmY-hP"
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h3mCeRBZj9J"
   },
   "outputs": [],
   "source": [
    "oldname = \"screenresolution\"\n",
    "newname = \"resolution\"\n",
    "\n",
    "df = df.rename(columns={oldname: newname})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWLvBcJlEaSs"
   },
   "source": [
    "## 6.3&nbsp;Check and handle Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRHZ2DqdN5BM"
   },
   "source": [
    "<b>pandas.isnull</b><br>\n",
    "Detect missing values for an array-like object.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.isnull.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0HuGiAoOYgR"
   },
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TildFw3KOf2_"
   },
   "source": [
    "<b>pandas.DataFrame.sum</b><br>\n",
    "Return the sum of the values over the requested axis (default: axis=0).<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNz_HLUcOyMT"
   },
   "source": [
    "Remark:<br>\n",
    "<b>In Python you can calculate with boolean values.<br>\n",
    "\"False\" corresponds to the value 0, \"True\" corresponds to the value 1.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Le2oeAOcOfG4"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o97dVs_IP7RQ"
   },
   "source": [
    "<b>pandas.DataFrame.dropna</b><br>\n",
    "Remove missing values.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWFrkNlaQhpW"
   },
   "source": [
    "<b>Delete every row, that has 'any' Null value in it:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvMFKedjP4_6"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(\n",
    "    how=\"any\", axis=0\n",
    ")  # Erase every row (axis=0) that has \"any\" Null value in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOs1fwwrLKZu"
   },
   "outputs": [],
   "source": [
    "# always check what you have done!\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GypaEwuDFfKc"
   },
   "source": [
    "## 6.4&nbsp;Check and change data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErScw_qdZuh7"
   },
   "source": [
    "<b>A change of the data type is mandatory, when a categorical variable has been coded as a number!<br>\n",
    "In this case, this means that you inform the dataframe that it is a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yei25iRJ-cnY"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqhfr5mK-cnY"
   },
   "source": [
    "We can see that the data types like 'float', 'integer' and 'object'.<br>\n",
    "'object' is for text or mixed text and numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWNSWnFDx7gD"
   },
   "source": [
    "<b>pandas.DataFrame.astype</b><br>\n",
    "Cast a pandas object to a specified dtype.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl7IfeX3R-1X"
   },
   "source": [
    "<b>Cast one single column to datatype 'category':</b><br>\n",
    "If several columns are to be cast, copy the code-cell and the column name adjusted (reproducibility).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc4XTEHuRpc8"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "col = 'ocean'                        # change column name\n",
    "df[col] = df[col].astype('category') # change type, e.g.: 'category', 'int', 'float', 'str'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kAEq8ZMBJ5h"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIiYd_kFSfyn"
   },
   "source": [
    "Remark: 'object' and 'categorial' are very similar.<br>\n",
    "When range of possible values is fixed and finite, categorial hat advantages resp. speed and memory.<br>\n",
    "It is also possible to order categories - then they become ordinal data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0f_41bmSliG"
   },
   "source": [
    "<b>Task: Cast column 'bedroom' to datatype 'integer':</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNOCL0PoMtLV"
   },
   "source": [
    "## 6.5&nbsp;Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cdgMgP0M1fS"
   },
   "outputs": [],
   "source": [
    "df = df.replace(\" \", \"\", regex=True)\n",
    "df = df.replace(\"-\", \"\", regex=True)\n",
    "df = df.replace(\"\\+\", \"\", regex=True)\n",
    "df = df.replace(\"/\", \"\", regex=True)\n",
    "df = df.replace(\".\", \"\", regex=False)\n",
    "df = df.replace(\"<\", \"\", regex=True)\n",
    "df = df.replace(\">\", \"\", regex=True)\n",
    "df = df.replace(\"\\[\", \"\", regex=True)\n",
    "df = df.replace(\"]\", \"\", regex=True)\n",
    "df = df.replace(\"\\(\", \"\", regex=True)\n",
    "df = df.replace(\"\\)\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWhd9LlDvRO9"
   },
   "source": [
    "## 6.6 Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFs12EH6vUk_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "oldvalue = 'old'     # change string\n",
    "newvalue = 'new'     # change string\n",
    "df = df.replace(oldvalue,newvalue , regex=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MwkNIprUvQq"
   },
   "source": [
    "## 6.7&nbsp;Replace rare values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Epff2tdUq1E"
   },
   "outputs": [],
   "source": [
    "rare = 10\n",
    "cols_cat = df.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns\n",
    "for col in cols_cat:\n",
    "    ToReplace = df[col].value_counts()[df[col].value_counts() < rare].index\n",
    "    for replace in ToReplace:\n",
    "        df = df.replace(replace, \"rare\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTJjH93EeKre"
   },
   "outputs": [],
   "source": [
    "col = [\"company\"]  # change column name\n",
    "print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxwxqbvXGWEt"
   },
   "source": [
    "# 7.&nbsp;Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCbjCtmPmKV9"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePpLVJJAktNX"
   },
   "source": [
    "## 7.1 Univariate - statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvrXnGeVltyF"
   },
   "source": [
    "<b><u>numerical columns<u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdEcbIY7Zv52"
   },
   "source": [
    "<b>pandas.DataFrame.describe</b><br>\n",
    "Generate descriptive statistics.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1A3yibDchR88"
   },
   "outputs": [],
   "source": [
    "df.describe().round(1)  # select a suitable number of decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJPDJjeERJY_"
   },
   "source": [
    "<u><b>categorial columns</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YRug-88NV27"
   },
   "outputs": [],
   "source": [
    "df.describe(include=[\"object\", \"string\", \"category\"])  # analysis of categorial columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCqkUR4hYwT1"
   },
   "source": [
    "<b>pandas.Series.value_counts</b><br>\n",
    "Return a Series containing counts of unique values.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FUAqy4CPy_D"
   },
   "outputs": [],
   "source": [
    "col = [\"company\"]  # change column name\n",
    "print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjHtc0c1nPgQ"
   },
   "source": [
    "## 7.2 Univariate - visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqYGNyjMtU7d"
   },
   "source": [
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KNks3WdntzQ"
   },
   "source": [
    "<b><u>Bar chart</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9U9pUC_UkJF"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "col   = 'gpu_company'                       # change column name\n",
    "kind  = 'bar'                               # 'bar': vertical bar plot, 'barh': horizontal bar plot\n",
    "title = 'Bar Chart - number of occurences'  # change title\n",
    "xlabel = 'Values of column \"' + col + '\"'   # change xlabel to ylabel, change string\n",
    "ylabel = 'Number'                           # change ylabbel to xlabel, change string\n",
    "width = 10                                  # change width\n",
    "height = 5                                  # change height\n",
    "\n",
    "df[col].value_counts().plot(kind=kind, title= title, xlabel= xlabel, ylabel= ylabel, figsize=(width, height));\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Udm2QHTIK8E7"
   },
   "source": [
    "<u><b>Histogram of all numerical variables</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgjONYo6R6YF"
   },
   "outputs": [],
   "source": [
    "# calculation recommended number of bins in histogram\n",
    "import math\n",
    "\n",
    "if df.shape[0] <= 1000:\n",
    "    bins = round(math.sqrt(df.shape[0]) + 0.5)\n",
    "else:\n",
    "    bins = round(10 * math.log10(df.shape[0]) + 0.5)\n",
    "print(\"Calculated recommended number of bins: \", bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpd-qwgLuQg_"
   },
   "outputs": [],
   "source": [
    "bins = 32  # change number of bins\n",
    "width = 12  # change width\n",
    "height = 10  # change height\n",
    "\n",
    "df.hist(bins=bins, figsize=(width, height));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fCXRRJbXynK"
   },
   "source": [
    "<b>Question:</b><br>\n",
    "What is the shape of the histograms? Do they have a bell shape?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa-jYKkBc_9G"
   },
   "source": [
    "<u><b>Creation of boxplots for all numerical variables</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcnQaqwK67_M"
   },
   "outputs": [],
   "source": [
    "kind = \"box\"\n",
    "title = \"Bar Chart - number of occurences\"  # change title\n",
    "width = 30  # change width\n",
    "height = 5  # change height\n",
    "\n",
    "df.plot(kind=kind, subplots=True, sharey=False, title=title, figsize=(width, height));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxSAc1KH8EUp"
   },
   "source": [
    "<u><b>Creation of boxplots of one numerical variable</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXWte_JG8BBZ"
   },
   "outputs": [],
   "source": [
    "col = \"inches\"  # change column name\n",
    "kind = \"box\"\n",
    "title = \"Boxplot\"  # change title\n",
    "width = 4  # change width\n",
    "height = 4  # change height\n",
    "\n",
    "df[col].plot(kind=kind, title=title, figsize=(width, height));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAkY1B7Vddgt"
   },
   "source": [
    "## 7.3&nbsp;Bivariate - correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tvM0AV0QeXC"
   },
   "source": [
    "<u><b>Show correlation matrix</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3jQWXv9fFbh"
   },
   "source": [
    "<b>pandas.DataFrame.corr</b><br>\n",
    "Compute pairwise correlation of columns, excluding NA/null values.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcvSa81N-FgK"
   },
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAx4hV3Kf9Ht"
   },
   "source": [
    "<b>Colors facilitate the analysis....</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGjc7mpcQyEL"
   },
   "source": [
    "<u><b>Show correlation heat map</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7mdNJUFgLiA"
   },
   "source": [
    "<b>seaborn.heatmap</b><br>\n",
    "Plot rectangular data as a color-encoded matrix.<br>\n",
    "https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0-sFy7M-cnd"
   },
   "outputs": [],
   "source": [
    "width = 4  # change width\n",
    "height = 4  # change height\n",
    "title = \"Correlation heat map\"  # change title\n",
    "\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.title(title)\n",
    "a = sns.heatmap(\n",
    "    df.corr(numeric_only=True),\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    linecolor=\"white\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    ")\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "a.set_yticklabels(a.get_yticklabels(), rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm5OqkcCgWM7"
   },
   "source": [
    "<b>Task: analyze the correlation matrix</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIK1Cv7mkatv"
   },
   "source": [
    "## 7.4&nbsp;Bivariate - visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdwGHz68PvhZ"
   },
   "source": [
    "<u><b>Pairplot: scatterplot of alle combinations of numerical features</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCGwwntx5VEv"
   },
   "source": [
    "<b>seaborn.pairplot</b><br>\n",
    "Plot pairwise relationships in a dataset.<br>\n",
    "https://seaborn.pydata.org/generated/seaborn.pairplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkdQo3XGO7IS"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkqD9_pSgw26"
   },
   "source": [
    "<b>Problem: overplotting!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXPCmWZn5zBs"
   },
   "source": [
    "<u><b>Scatterplot of two numerical features</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-4LTIushQ2R"
   },
   "source": [
    "<b>pandas.DataFrame.plot</b><br>\n",
    "Make plots of Series or DataFrame.<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8kyShBWcokd"
   },
   "outputs": [],
   "source": [
    "# Show numerival features\n",
    "df.select_dtypes(include=[\"float\", \"int\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05zROIWS58Bd"
   },
   "outputs": [],
   "source": [
    "col_x = \"weight\"  # column for x-axis\n",
    "col_y = \"price\"  # column for y-axis\n",
    "width = 4  # change width\n",
    "height = 4  # change height\n",
    "title = \"Scatterplot: \" + col_y + \" vs. \" + col_x\n",
    "alpha = 0.1  # regulate the transparency of a graph plot using the alpha attribute.\n",
    "\n",
    "df.plot.scatter(title=title, x=col_x, y=col_y, alpha=alpha, figsize=(width, height));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZE2IJmt4HJt"
   },
   "source": [
    "<b>Question:</b><br>\n",
    "How is the relationship between price with RAM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl8VjBmbOpZy"
   },
   "source": [
    "<u><b>Creation of \"side-by-side\" boxplots</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPL_bwa1eEoI"
   },
   "outputs": [],
   "source": [
    "print(\"Numerical features:\")\n",
    "print(df.select_dtypes(include=[\"float\", \"int\"]).columns)\n",
    "print(\"Categorial features:\")\n",
    "print(df.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEsPMHnpevZ6"
   },
   "outputs": [],
   "source": [
    "target = \"price\"  # change column name\n",
    "width = 8  # change width\n",
    "height = 4  # change height\n",
    "rotation = 90  # change orientation degree x-label\n",
    "\n",
    "col_categorial = df.select_dtypes(\n",
    "    include=[\"object\", \"string\", \"category\"]\n",
    ")  # column names of categorials\n",
    "\n",
    "for col in col_categorial:\n",
    "    plt.figure(figsize=(width, height))\n",
    "    title = \"Boxplots: \" + target + \" vs. \" + col\n",
    "    ax = sns.boxplot(x=df[col], y=df[target])\n",
    "    plt.setp(ax.get_xticklabels(), rotation=rotation)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2g8ckQlGPxp"
   },
   "source": [
    "## 7.5 Trivariate - visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKdhY_-V5QIL"
   },
   "source": [
    "<u><b>Scatterplot of selected two features with color-information of third feature</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3g0IZac619cG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "col_x     = 'RAM'         # change column name (for x axis)\n",
    "col_y     = 'Weight'      # change column name (for y axis)\n",
    "var_color = 'Price'       # change column name (different colors)\n",
    "alpha     =  0.2          # change parameter to see density of data points\n",
    "width  = 5                # change width\n",
    "height = 3                # change height\n",
    "\n",
    "df.plot(kind=\"scatter\", x=col_x, y=col_y, alpha=alpha,\n",
    "        c = var_color,  cmap=plt.get_cmap(\"jet\"), colorbar=True, figsize=(width, height));\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ1vAcJGTFPs"
   },
   "source": [
    "# 8&nbsp;Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrKTE8fqTLfT"
   },
   "source": [
    "## 8.1&nbsp;Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "et8vFWPrTYpk"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5etAZm3RtWpT"
   },
   "source": [
    "<b>The task is to generate features, that (probably) have a high correlation with the target.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Kdc7g6ASP7t"
   },
   "outputs": [],
   "source": [
    "df[\"weight2\"] = df.weight**2  # change column names and formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qpeg49bcGpmH"
   },
   "outputs": [],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIN5GamM6wxz"
   },
   "source": [
    "Do you have any additional suggestions for features engineering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90UUIu6vt8sV"
   },
   "source": [
    "<b>The correlations of all features with the target are shown.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hrKaNulSP_0"
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr(numeric_only=True)\n",
    "corr_matrix[target].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6RIxvHtfkLM"
   },
   "source": [
    "## 8.2&nbsp;Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HRsKHkMvY-3"
   },
   "source": [
    "In lineare regression: scaling is not mandantory.<br>\n",
    "Scaling may help here, that the parameters are more understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m71rGjT7g4y"
   },
   "source": [
    "<b>Show min, median and max of every feature</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdNXzfLVgJ_0"
   },
   "outputs": [],
   "source": [
    "df.describe().loc[[\"min\", \"50%\", \"max\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izwZ46y9S_Ug"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# example for scaling\n",
    "df.price = df.price / 1000          # change column name and scaling number\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_7wTiUBKSMu"
   },
   "source": [
    "## 8.3&nbsp;Delete data records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fosS0WKrKjhh"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "col    = 'column'                        # change column\n",
    "df = df[ df[col] <= 500 ]    # keep only records that fulfill this condition\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFMmllyVFEIF"
   },
   "source": [
    "# 9.&nbsp;Split Data (Train + Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ky1ze5VUg2Y"
   },
   "source": [
    "<b>sklearn.model_selection.train_test_split</b><br>\n",
    "Split arrays or matrices into random train and test subsets.<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4R73FjATovb"
   },
   "outputs": [],
   "source": [
    "seed = 12345  # change seed, to get another split\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=seed\n",
    ")  # change proportion of the dataset to include in the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZ_QkDyvIFmk"
   },
   "outputs": [],
   "source": [
    "print(\"Shape from df_train:\", df_train.shape)\n",
    "print(\"Shape from df_test:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMouTsyF-cnf"
   },
   "source": [
    "# 10.&nbsp;Create Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aje3TWcbnPGR"
   },
   "source": [
    "## 10.1&nbsp;Fit linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3oFy8rkZPFW"
   },
   "source": [
    "<b>statsmodels.regression.linear_model.OLS.fit</b><br>\n",
    "Full fit of the model.<br>\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.fit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydLwtNKv6NcU"
   },
   "source": [
    "<ul>\n",
    "<li>To create a linear model, you must define the target, and the features you'd like to use.\n",
    "<li>The colnames of categorials must be put in C() - or you encode them before.\n",
    "<li><b>Syntax:</b><br>\n",
    "    name_of_model = smf.OLS(formula = target ~ feature1 + feature2 + ..., data=df).fit()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOe4Qerqhusd"
   },
   "outputs": [],
   "source": [
    "target = \"price\"  # change column name - which variable is the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2HXD6BmdAhh"
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfgBXUdc_hUP"
   },
   "source": [
    "<b>It makes sense to primarily use the features with the highest absolute correlation to the target.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8ThGIRRcslh"
   },
   "outputs": [],
   "source": [
    "corr_matrix = df_train.corr(numeric_only=True)\n",
    "ct = corr_matrix[target].abs().sort_values(ascending=False)  # ct: correlation target\n",
    "ct.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-gX4Bv-dMr1"
   },
   "source": [
    "<b>We start using features with the highest absolute correlations to the target.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSGUbrgRc9hb"
   },
   "outputs": [],
   "source": [
    "# del lm05\n",
    "formula05 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + C(cpu_company) + gpu_company + typename + opsys + company\"\n",
    ")\n",
    "lm05 = smf.ols(formula=formula05, data=df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjbCSzSJIZea"
   },
   "outputs": [],
   "source": [
    "formula01 = target + \"~ ram + cpu_frequency + weight2 + weight + inches\"\n",
    "formula02 = target + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company\"\n",
    "formula03 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company\"\n",
    ")\n",
    "formula04 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company + typename\"\n",
    ")\n",
    "formula05 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company + typename + opsys\"\n",
    ")\n",
    "formula06 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company + typename + opsys + company\"\n",
    ")\n",
    "formula07 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company + typename + opsys + company + resolution\"\n",
    ")\n",
    "formula08 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company + typename + opsys + company + resolution + memory\"\n",
    ")\n",
    "formula09 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company + typename + opsys + company + resolution + memory + cpu_type\"\n",
    ")\n",
    "formula09 = (\n",
    "    target\n",
    "    + \"~ ram + cpu_frequency + weight2 + weight + inches + cpu_company + gpu_company + typename + opsys + company + resolution + memory + cpu_type + gpu_type\"\n",
    ")\n",
    "\n",
    "lm01 = smf.ols(formula=formula01, data=df_train).fit()\n",
    "lm02 = smf.ols(formula=formula02, data=df_train).fit()\n",
    "lm03 = smf.ols(formula=formula03, data=df_train).fit()\n",
    "lm04 = smf.ols(formula=formula04, data=df_train).fit()\n",
    "lm05 = smf.ols(formula=formula05, data=df_train).fit()\n",
    "lm06 = smf.ols(formula=formula06, data=df_train).fit()\n",
    "lm07 = smf.ols(formula=formula07, data=df_train).fit()\n",
    "lm08 = smf.ols(formula=formula08, data=df_train).fit()\n",
    "lm09 = smf.ols(formula=formula09, data=df_train).fit()\n",
    "\n",
    "models = [\n",
    "    lm01,\n",
    "    lm02,\n",
    "    lm03,\n",
    "    lm04,\n",
    "    lm05,\n",
    "    lm06,\n",
    "    lm07,\n",
    "    lm08,\n",
    "    lm09,\n",
    "]  # we collect the four linear models in the variable 'models'\n",
    "model_name = [\n",
    "    \"lm01\",\n",
    "    \"lm02\",\n",
    "    \"lm03\",\n",
    "    \"lm04\",\n",
    "    \"lm05\",\n",
    "    \"lm06\",\n",
    "    \"lm07\",\n",
    "    \"lm08\",\n",
    "    \"lm09\",\n",
    "]  # we store the names of the model in 'model_name'\n",
    "formulas = [\n",
    "    formula01,\n",
    "    formula02,\n",
    "    formula03,\n",
    "    formula04,\n",
    "    formula05,\n",
    "    formula06,\n",
    "    formula07,\n",
    "    formula08,\n",
    "    formula09,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRjbug3xcCJk"
   },
   "outputs": [],
   "source": [
    "print(lm05.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfPqvcEflgYU"
   },
   "source": [
    "## 10.2&nbsp;Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mssTUE6pOtgz"
   },
   "outputs": [],
   "source": [
    "def plot_pred_target(df, target, model, modelname, fit=1):\n",
    "    var_x = df[target]  # insert column name for x axis here!\n",
    "    alpha = 0.1  # parameter to see density of data points\n",
    "    if fit:\n",
    "        plt.title(\"Scatterplot: Fitted vs. Target, model: \" + modelname, fontsize=16)\n",
    "        plt.ylabel(\"fitted \" + target, fontsize=15)\n",
    "        var_y = model.fittedvalues  # insert column name for y axis here!\n",
    "    else:\n",
    "        plt.title(\"Scatterplot: Predicted vs. Target, model: \" + modelname, fontsize=16)\n",
    "        plt.ylabel(\"predicted \" + target, fontsize=15)\n",
    "        var_y = model.predict(df)  # insert column name for y axis here!\n",
    "    maxvalue = max(max(var_x), max(var_y)) * 1.05\n",
    "    minvalue = min(-5, min(var_x), min(var_y)) * 1.05\n",
    "    plt.scatter(var_x, var_y, alpha=alpha)\n",
    "    plt.grid()\n",
    "    plt.xlim([minvalue, maxvalue])\n",
    "    plt.ylim([minvalue, maxvalue])\n",
    "    plt.xlabel(target, fontsize=15)\n",
    "    plt.plot([minvalue, maxvalue], [minvalue, maxvalue], color=\"red\")\n",
    "    plt.axvline(0, color=\"black\")  # vertical\n",
    "    plt.axhline(0, color=\"black\")  # horizontal\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_Hz_47bqC-c"
   },
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    plot_pred_target(df_train, target, models[i], model_name[i], fit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH3Aq0d7CHm-"
   },
   "source": [
    "<ul>\n",
    "<li>Various pieces of information are stored in our linear models (RegressionResultsWrappers).\n",
    "<li>The \"fittedvalues\" are the predicted values based on the training data.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0jTdV2qQY8y"
   },
   "outputs": [],
   "source": [
    "lm = lm04\n",
    "print(\"Parameters:\")\n",
    "print(lm.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbGunjRHMiFb"
   },
   "source": [
    "## 10.3&nbsp;R2, adj. R2 and RMSE (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZaAXlmaM8q5"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(\"Training Data\")\n",
    "print(\"Name\", \" R2\", \"    adj R2\")\n",
    "for model in models:\n",
    "    print(\n",
    "        model_name[i],\n",
    "        \"\",\n",
    "        \"{:.2f}\".format(model.rsquared),\n",
    "        \" \",\n",
    "        \"{:.2f}\".format(model.rsquared_adj, 3),\n",
    "    )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuJ4fi61XS0K"
   },
   "source": [
    "Adjusted R2 is a key figure to compare lineare models with different numbers of features.<br>\n",
    "Adjusted R2 is less equal than R2 and peanlizes any additional feature.<br>\n",
    "R2(training) always decreases, when additional features are added, for adjsuted R2 this is not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNoVCywDQHhz"
   },
   "source": [
    "<b>Task: Analyze the results</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Blw07wV6NhuB"
   },
   "source": [
    "<u><b>Print summary of the full model</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpxtzd6yNiFC"
   },
   "outputs": [],
   "source": [
    "lm = lm09\n",
    "print(lm.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlszbDSwSA65"
   },
   "source": [
    "## 10.4&nbsp;Summary table - upper area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4JEPhFLQr3y"
   },
   "source": [
    "\n",
    "\\begin{array}{|l|l|} \\hline\n",
    "\\text{Model:} & \\text{OLS stands for Ordinary Least Square.} \\\\\n",
    " & \\text{The model tries to find out a linear function which minimizes the sum of residual squares} \\\\ \\hline\n",
    "\\text{Dep Variable:} & \\text{Name of the dependent variable} \\\\ \\hline\n",
    "\\text{Date:} & \\text{Timestamp of creation of this OLSResults-Object} \\\\ \\hline\n",
    "\\text{No Obs.:} & \\text{Number of observations} \\\\ \\hline\n",
    "\\text{Df Model:} & \\text{Degrees of freedom of the model (# of independent features)} \\\\ \\hline\n",
    "\\text{Df Residuals:} & \\text{Degrees of freedom of the residuals (# Observations - Df Model - 1)} \\\\ \\hline\n",
    "\\text{R-squared:} & R^2: \\text{coefficient of determination} \\\\ \\hline\n",
    "\\textbf{Adj. R-squared:} & R^2 \\text{ is adjusted to the number of features, goal: to maximize} \\\\  \\hline\n",
    "\\text{AIC:} & \\text{Akaike's information criteria, goal: to minimize} \\\\ \\hline\n",
    "\\text{BIC:} & \\text{Bayes' information criteria, goal: to minimize} \\\\ \\hline\n",
    "\\text{Log-Likel.hood:} & \\text{The higher the value, the better the model fits the given data.} \\\\ \\hline\n",
    "\\text{F-statistic:} & \\text{F-test: check if all features together are related to the dependent variable.} \\\\ \\hline\n",
    "\\textbf{Prob (F-stat):} & \\text{<0.05:   at least one feature is significantly related with the output} \\\\\n",
    "& \\text{>=0.05: no evidence of relationship between any of the features with the output}\n",
    " \\\\ \\hline\n",
    "\\text{Scale:} & \\text{The Default value is ssr/(n-p)} \\\\\n",
    "              & \\text{ssr = Sum of squared (whitened) residuals.} \\\\\n",
    "              & \\text{n-p = (# observations - # parameters)} \\\\ \\hline\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/simple-explanation-of-statsmodel-linear-regression-model-summary-35961919868b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xI7Z33njTdnS"
   },
   "source": [
    "## 10.5&nbsp;Summary table - middle area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daca9uN1YTpx"
   },
   "outputs": [],
   "source": [
    "print(lm.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5QahjIGYXPh"
   },
   "source": [
    "**The following values are given for the intercept and every feature:**\n",
    "\n",
    "\\begin{array}{|l|l|} \\hline\n",
    "\\textbf{Coef.} & \\text{The estimated coefficient value} \\\\ \\hline\n",
    "\\text{Std.Err.} & \\text{The standard error of the coefficient measures - how precisely the coefficient's value is estimated} \\\\ \\hline\n",
    "\\text{t} & \\text{t-value = Coef. / Std.Err.} \\\\ \\hline\n",
    "\\textbf{P>|t|} & \\text{p-value of this t-statistic} \\\\\n",
    "   & \\text{A low p-value (< 0.05) means that the coefficient is likely not to equal zero} \\\\\n",
    "   & \\text{A high p-value (> 0.05) means that we cannot conclude that the feature affects the outcome} \\\\ \\hline\n",
    "\\text{[0.025 ; 0.975]} & \\text{To information: coef. are exactly in the middle of this interval} \\\\\n",
    "& \\text{Set of values for which a hypothesis test to the level of 5% cannot be rejected} \\\\ \\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMUwWxs5UTfy"
   },
   "source": [
    "## 10.6&nbsp;Summary table - lower area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaEWif9Rfu9e"
   },
   "outputs": [],
   "source": [
    "print(lm.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QebLRChVfxzk"
   },
   "source": [
    "**If the data is good for modeling, then our residuals will have certain characteristics. This is checked here.**\n",
    "\n",
    "\\begin{array}{|l|l|} \\hline\n",
    "\\text{Omnibus:} & \\text{A test of the skewness and kurtosis of the residual.} \\\\\n",
    "& \\text{We hope to see a value close to zero which would indicate normalcy.} \\\\ \\hline\n",
    "\\text{Prob(Omnibus):} & \\text{Performs a statistical test indicating the probability that the residuals are normally distributed.} \\\\\n",
    "&  \\text{We hope to see something close to 1 here.} \\\\\n",
    "& \\text{Chance that the residuals the normally distributed.} \\\\ \\hline\n",
    "\\text{Skew} & \\text{A measure of data symmetry.} \\\\\n",
    "& \\text{We want to see something close to zero, indicating the residual distribution is normal.} \\\\\n",
    "& \\text{ Note that this value also drives the Omnibus.} \\\\ \\hline\n",
    "\\text{Kurtosis:} & \\text{A measure of \"peakiness\", or curvature of the data.} \\\\\n",
    "& \\text{Higher peaks lead to greater Kurtosis.} \\\\\n",
    "& \\text{Greater Kurtosis can be interpreted as a tighter clustering of residuals around zero.} \\\\ \\hline\n",
    "\\text{Durbin-Watson:} & \\text{Test for homoscedasticity. We hope to have a value between 1 and 2.} \\\\ \\hline\n",
    "\\text{Jarque-Bera (JB):} & \\text{Test like the Omnibus test, in that it tests both skew and kurtosis.} \\\\ \\hline\n",
    "\\text{Prob(JB)} & \\text{We hope to see in this test a confirmation of the Omnibus test.} \\\\ & \\text{We hope to see something close to 1 here.} \\\\ \\hline\n",
    "\\text{Condition Number} & \\text{This test measures the sensitivity of a function's output as compared to its input.} \\\\\n",
    "& \\text{When we have multicollinearity, we can expect much higher fluctuations to small changes in the data.} \\\\\n",
    "& \\text{Hence, we hope to see a relatively small number, something below 30.} \\\\ \\hline\n",
    "\\end{array}\n",
    "\n",
    "https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_TbhZWqvVtn"
   },
   "source": [
    "# 11&nbsp;Check performance with test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7K02xrwRS_z"
   },
   "source": [
    "##&nbsp;11.1 Extra categories in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkeQ1-iTTnkQ"
   },
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LnnNjyvRfvv"
   },
   "outputs": [],
   "source": [
    "cols_cat = df.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns\n",
    "for col in cols_cat:\n",
    "    df_test = df_test[df_test[col].isin(df_train[col].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1_5KB64Tqfw"
   },
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "547usJWmTTIy"
   },
   "source": [
    "##&nbsp;11.2 R2 and RMSE (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcWWN7AqRgFm"
   },
   "source": [
    "The model with <b>maximum $R^2$</b> respective <b>minimal RMSE</b> is to selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8Je4z0-xhDk"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "y_test = df_test[target]\n",
    "\n",
    "print(\"Test Data\")\n",
    "print(\"Name\", \" R2\", \"   RMSE\")\n",
    "for model in models:\n",
    "    y_pred = model.predict(df_test)\n",
    "    resid = y_test - y_pred\n",
    "    print(\n",
    "        model_name[i],\n",
    "        \"\",\n",
    "        \"{:.2f}\".format(r2_score(y_pred, y_test)),\n",
    "        \"\",\n",
    "        \"{:.0f}\".format(root_mean_squared_error(y_test, y_pred)),\n",
    "    )\n",
    "    # list(model.params.index[1:100])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA4XiGbji5HS"
   },
   "source": [
    "<b>Question:</b><br>\n",
    "What model performs best?<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spdau6U7OdH8"
   },
   "outputs": [],
   "source": [
    "lm = lm09\n",
    "lm_name = \"lm09\"\n",
    "y_pred = lm.predict(df_test)\n",
    "\n",
    "plot_pred_target(df_test, target, lm, \"lm_name\", fit=0)\n",
    "print(\"R2: \", round(r2_score(y_pred, y_test), 2))\n",
    "print(\"Mean Residual: \", round(np.mean(y_test - y_pred), 2))\n",
    "print(\"RMSE: \", round(root_mean_squared_error(y_test, y_pred), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBOrQfCB2dM5"
   },
   "outputs": [],
   "source": [
    "lm = lm08\n",
    "lm_name = \"lm08\"\n",
    "y_pred = lm.predict(df_test)\n",
    "plot_pred_target(df_test, target, lm, \"lm08\", fit=0)\n",
    "print(\"R2: \", round(r2_score(y_pred, y_test), 2))\n",
    "print(\"Mean Residual: \", round(np.mean(y_test - y_pred), 2))\n",
    "print(\"RMSE: \", round(root_mean_squared_error(y_test, y_pred), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dEzfm82cwgv"
   },
   "source": [
    "##&nbsp;11.3 Residual plot (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFiak4uQRM19"
   },
   "outputs": [],
   "source": [
    "y_pred = lm09.predict(df_test)\n",
    "plt.scatter(y_pred, y_test - y_pred)\n",
    "plt.plot([min(y_pred), max(y_pred)], [0, 0], color=\"red\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.xlabel(\"Predictions\", fontsize=15)\n",
    "plt.ylabel(\"Residuals\", fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okVSDzBma6KM"
   },
   "source": [
    "<b>Task: try to produce overfitting!</b>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1E24q-D_lz3-rDz7Ulk6PDcUA-ZwUWXEf",
     "timestamp": 1700066443298
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
